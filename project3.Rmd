---
title: "Project3"
author: "Group 6"
date: "4/2/2020"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(caret)
library(MASS)
library(BART)
```


```{r}
absent <-read.csv("Absenteeism_at_work2.csv")
str(absent)
```

```{r}
##Converting into factors
#absent$ï..ID<- as.factor(absent$ï..ID)
absent$Reason.for.absence <- as.factor(absent$Reason.for.absence)
absent$Month.of.absence <- as.factor(absent$Month.of.absence)
absent$Day.of.the.week <- as.factor(absent$Day.of.the.week)
absent$Seasons <- as.factor(absent$Season)
absent$Disciplinary.failure <-as.factor(absent$Disciplinary.failure)
absent$Education <- as.factor(absent$Education)
absent$Social.drinker <-as.factor(absent$Social.drinker)
absent$Social.smoker <-as.factor(absent$Social.smoker)
absent$ï..ID  <- NULL
absent$Work.load.Average.day<-as.numeric(absent$Work.load.Average.day)
absent$Month.of.absence<- NULL
absent$Weight<- NULL
absent$is_Thur<-if_else(absent$Day.of.the.week==5,1,0)
absent$Day.of.the.week<-NULL
absent$is_Seas4<-if_else(absent$Seasons==4,1,0)
absent$Seasons<-NULL
#absent$is_Educ3<-if_else(absent$Education==3,1,0) Once I do this, Seasons and Education3 no longer significant
#absent$Education<-NULL
absent$Transportation.expense<-NULL
absent$Social.drinker<-NULL
absent$Disciplinary.failure<-NULL

lm.model <- lm( Absenteeism.time.in.hours ~., data=absent)
stepmodel <- step(lm.model, direction = "forward")
summary(stepmodel)

lm1 <-lm(Absenteeism.time.in.hours ~.,data=absent) %>% stepAIC(trace = FALSE, direction = "forward")
summary(lm1)
# ANN/Decision tree/Logistic Rminer?
```

# ANN/Decision tree/Logistic Rminer?
Reason for absense: Overall reasons for absence are significant, but some reasons have more of impact than others. I guess that's because some reasons are commonplace or popular while others are more personal and not widely used.

Month of absence:It is not a significant factor, however by common sense, we would expect people to take more leaves during holiday season,such as Christams and New Year Holiday,and take less leaves after that, which is the first quarter of the year.

Day of the Week: Comparatively, people take more leaves in the first few days of the week, one possible explanation is people tend to have "Monday Syndrome", and in the last few workdays(Thursdays and Fridays) they tend to work harder and longer to finish the work in time in order to have a good weekend.

Seasons: Similar to Month of absense. We can see people take longer leaves during season 2,3,4 than season 1, I guess that's because in season 1 most people just come back from Christmas and New Year Holiday, and there are less holidays in season 1.

Transportation expense: We expected that people who need more transportation expenses tend to have more absense. Interestingly, the coefficient is postive but really small, also it is not significant. I guess this is because most people won't consider transportation expenses when they are thinking if they want to go to work today (since you can make more money than transportation expenses if you work)

Distance from Residence to Work: The result is kind of counterintuitive since we expectd that people who liver closer to the company will show up more compared to people who don't. Though it is not significant, the relationship is negative. Maybe it is becuase people who liver closer tend to procrastinate and leave home later than people who live farther away and get up earlier.

Service time:Intuitively, people who do more volunteer work would of course ask for more leaves than people who don't.

Age:Older people may ask for more leaves due to health issues, or because they are more senior so the legwork can be handed to juniors and they can leave earlier.

Work load Average day:The coefficient is negative, which is straigtforward because the more workload you have the less likely you will take a break.

Hit target:If you have hit the target of your manager/your team, you can be rewarded with more breaks.

Education:The higher degree you have, the more capable you are and therefore, you will need to handle more challenging work that may require more time.

Son:It is pretty straightforward that more kids means people need more commitment to the family and more parental leaves, therefore the relationship is negative.

Social drinker: ?

Social smoker: ?

Pet:We expected it to be similar to "Son", however the relationship is negative. One possible interpreation is that people who have pets are mostly young people who don't have kids. Also, pets need less dedication that kids(since you don't need to cook for pets and tutor them)


Weight, Height, Body mass index:We expected a healthy body would save people from taking sick leaves. Weight and height are very insignificant since people with different heights have different healthy weights. BMI index is also significant since a good BMI is between 18.5-24.9——neither a too high or too low BMI index is good.


Preparing the data
```{r}
##Randomizing the data
set.seed(65)
absent_r<-absent[sample(nrow(absent)),]

##Turning factors into binary
absent_mm <- as.data.frame(model.matrix(~ . -1, absent_r)) ##Breaking factors into dummy variables


normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

##Normalizing every variable except output
absent_n <- as.data.frame(lapply(subset(absent_mm,select=c(-Absenteeism.time.in.hours)), normalize))
```
## ANN Model

```{r}
##Dividing response variable into categories 
absent$timecat <- absent$Absenteeism.time.in.hours
absent$timecat <- ifelse(absent$timecat == 0, "Not Absent", ifelse (absent$timecat>0 & absent$timecat<8, "<1 day", ifelse(absent$timecat>=8 & absent$timecat<=32, "1-4 days", ifelse(absent$timecat>32 & absent$timecat<=56, "1 week", ifelse(absent$timecat>56 & absent$timecat<=96, "2 weeks", "3 weeks")))))
          
absent$timecat <- as.factor(absent$timecat)
absent$onehot <- class.ind(absent$timecat)

#Randomizing and Normalizing
absent2 <- absent #creating dummy data frame to work on 
absent2$Absenteeism.time.in.hours <- NULL
absent2$timecat <- NULL
#View(absent2)
set.seed(65)
abs2_random<-absent2[sample(nrow(absent2)),]
abs2_mm<- model.matrix(~.-1, data=abs2_random[-20]) #removing intercept from -1

normalize<-function(x){
  return((x-min(x))/(max(x)-min(x)))
}

abs2_normal<-as.data.frame(lapply(abs2_mm[1:19],normalize))
```

#Decision Tree
```{r}
## Understanding Decision Trees ----
# calculate entropy of a two-class segment
-0.60 * log2(0.60) - 0.40 * log2(0.40)

curve(-x * log2(x) - (1 - x) * log2(1 - x),
      col="red", xlab = "x", ylab = "Entropy", lwd=4)

## Example: Identifying Risky Bank Loans ----
## Step 2: Exploring and preparing the data ----

# create a random sample for training and test data
# use set.seed to use the same random number sequence as the tutorial
set.seed(12345)

abs2_random$onehot <-as.factor(abs2_random$onehot)
# split the data frames
abs_train <- absent_r[1:640, ]
abs_test  <- absent_r[641:740, ]

# check the proportion of class variable
prop.table(table(abs_train$timehot))
prop.table(table(abs_test$timehot))

## Step 3: Training a model on the data ----
# build the simplest decision tree
library(C50)
abs_model <- C5.0(abs_train[-21], abs_train$timecat)

# display simple facts about the tree
abs_model

# display detailed information about the tree
summary(abs_model)

#plot(credit_model)

#mod1 <- C5.0(Species ~ ., data = iris)
#plot(mod1)

## Step 4: Evaluating model performance ----
# create a factor vector of predictions on test data
abs_pred <- predict(abs_model, abs_test)

# cross tabulation of predicted versus actual classes
library(gmodels)
CrossTable(abs_test$timecat, abs_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual timecat', 'predicted timecat'))

## Step 5: Improving model performance ----

## Boosting the accuracy of decision trees
# boosted decision tree with 10 trials
abs_boost10 <- C5.0(abs_train[-21], abs_train$timecat,
                       trials = 10)
abs_boost10
summary(abs_boost10)

abs_boost_pred10 <- predict(abs_boost10, abs_test)
CrossTable(abs_test$timecat, abs_boost_pred10,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual timecat', 'predicted timecat'))

# boosted decision tree with 100 trials (not shown in text)
abs_boost100 <- C5.0(abs_train[-21], abs_train$timecat,
                        trials = 100)
abs_boost_pred100 <- predict(abs_boost100, abs_test)
CrossTable(abs_test$timecat, abs_boost_pred100,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))

## Making some mistakes more costly than others
# create a cost matrix
error_cost <- matrix(c(0, 1, 4, 0,0,1,4,0,0,1,4,0,0,1,4,0,0,1,4,0,0,1,4,0,0,1,4,0,0,1,4,0,0,1,4,0), nrow = 6)
error_cost

# apply the cost matrix to the tree
abs_cost <- C5.0(abs_train[-21], abs_train$timecat,
                          costs = error_cost)
abs_cost_pred <- predict(abs_cost, abs_test)

CrossTable(abs_test$timecat, abs_cost_pred,
           prop.chisq = FALSE, prop.c = FALSE, prop.r = FALSE,
           dnn = c('actual default', 'predicted default'))


```

